{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `sybil2` as a conda environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from argparse import Namespace\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import numpy as np\n",
    "from segmentation_evaluator_new import NoduleSegmentEvaluator\n",
    "# sys.path.append('/data/rbg/users/pgmikhael/current/SybilX')\n",
    "sys.path.append('/data/rbg/users/erubel/sybil/SybilX')\n",
    "from sybilx.utils.registry import get_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotations_mask(slice_ids, shape):\n",
    "    slice_ids = [p.split('/')[-1].split('.dcm')[0] for p in row['paths']]\n",
    "    mask = torch.zeros(shape)\n",
    "    W, H = mask.shape[1:]\n",
    "    for i, slice in enumerate(slice_ids):\n",
    "        for bbox in annots.get(slice, []):\n",
    "            x_left, y_top = bbox[\"x\"] * W, bbox[\"y\"] * H\n",
    "            x_right, y_bottom = x_left + bbox[\"width\"] * W, y_top + bbox[\"height\"] * H\n",
    "            x_left, y_top = math.floor(x_left), math.floor(y_top)\n",
    "            x_right, y_bottom = math.ceil(x_right), math.ceil(y_bottom)\n",
    "            mask[i,y_top:y_bottom, x_left:x_right] = 1\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 15000/15000 [00:01<00:00, 9727.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contructed NLST CT Cancer Risk test dataset with 1633 records, 1633 exams, 788 patients, and the following class balance \n",
      " Counter({1: 1606, 0: 27})\n",
      "Censor Times: Counter({0: 554, 1: 349, 2: 263, 3: 184, 4: 156, 5: 127})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "annotations = json.load(open(\"/data/rbg/shared/datasets/NLST/NLST/annotations_122020.json\", \"r\"))\n",
    "args = Namespace(**pickle.load(open('/data/rbg/users/pgmikhael/current/SybilX/logs/c32cb085afbe045d58a7c83dcb71398c.args', 'rb')))\n",
    "nodule_dataset = pd.read_csv('/data/rbg/users/pgmikhael/current/SybilX/notebooks/NoduleGrowth/nlst_cancer_nodules.csv')\n",
    "dataset = get_object(args.dataset, 'dataset')(args, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = NoduleSegmentEvaluator(min_cluster_size=25)\n",
    "\n",
    "# mask_dir = \"/data/rbg/scratch/lung_ct/e31840e7efe14a10472d817f8a14b27f\" # BMP3D finetuned\n",
    "# mask_dir = \"/data/rbg/scratch/lung_ct/epoch=7\" # BMP2D finetuned\n",
    "# mask_dir = \"/data/rbg/scratch/lung_ct/0f18c617a2f6b5a768d81c7465e206f2epoch=12\" # TSM 1\n",
    "mask_dir = \"/data/rbg/scratch/lung_ct/aeec028d12497e8dcd29cdf025dfb675epoch=0\" # TSM 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|█▊                                                           | 50/1633 [00:33<17:34,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "nodule_identification = []\n",
    "dices = []\n",
    "for i, row in tqdm(enumerate(dataset.dataset), total=len(dataset.dataset), ncols=100):\n",
    "    exam = row['exam']\n",
    "\n",
    "    nodule_row = nodule_dataset[nodule_dataset['PID'] == int(row['pid'])]\n",
    "    tp = row['screen_timepoint']\n",
    "\n",
    "    if isinstance(nodule_row[f\"Annotated_{tp}\"].iloc[0], str): # has annotation\n",
    "        annotated_sid = [s for s in nodule_row[f\"Annotated_{tp}\"].iloc[0].split(';') if s == row['series']]\n",
    "\n",
    "        if len(annotated_sid) == 0: continue\n",
    "\n",
    "        annots = annotations[annotated_sid[0]]\n",
    "        slice_ids = [p.split('/')[-1].split('.dcm')[0] for p in row['paths']]\n",
    "\n",
    "        segmentation = pickle.load(open(f\"{mask_dir}/sample_{exam}.hiddens\", \"rb\"))[\"hidden\"][0]\n",
    "\n",
    "        # nodule identification according to export annotation\n",
    "        mask1 = get_annotations_mask(slice_ids, segmentation.shape)\n",
    "\n",
    "        nodule_identification.append(((mask1 * segmentation).sum() > 0).item())\n",
    "        dices.append(\n",
    "            evaluator.get_scan_wise_dice(mask1[None].numpy(), segmentation[None].numpy()).item()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodule Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nodule Recall: {len([val for val in nodule_identification if val]) / len(nodule_identification)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Dice: 0.10016806180666785\n",
      "Median Dice: 6.728539574396564e-06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean Dice: {np.mean(dices).item()}\\nMedian Dice: {np.median(dices).item()}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sybil2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
